{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigearthnet_encoder.encoder import tiff_dir_to_ben_s2_patch\n",
    "from bigearthnet_common.example_data import get_s2_example_folder_path\n",
    "\n",
    "s2_path = get_s2_example_folder_path()\n",
    "example_patch = [p for p in s2_path.iterdir()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_patch = tiff_dir_to_ben_s2_patch(example_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# 160KB per patch with all bands\n",
    "patch_size_in_bytes = sys.getsizeof(s2_patch.dumps())\n",
    "patch_size_in_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**30 // patch_size_in_bytes\n",
    "# around 6600 patches per GB\n",
    "# 80~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmdb\n",
    "from rich.progress import Progress\n",
    "from bigearthnet_patch_interface.s2_interface import BigEarthNet_S2_Patch\n",
    "import bigearthnet_common.constants as ben_constants\n",
    "from typing import List\n",
    "\n",
    "SHARD_SIZE = 6600\n",
    "BATCH_SIZE = 16\n",
    "REPS = 2\n",
    "TOTAL_TEST_SIZE = SHARD_SIZE * REPS\n",
    "\n",
    "\n",
    "def interpolate_to_ben_perf(size, seconds):\n",
    "    interpolated_seconds = ben_constants.BEN_COMPLETE_SIZE / size * seconds\n",
    "    return f\"Would take {interpolated_seconds / 60:.02} min to pass through BigEarthNet\"\n",
    "\n",
    "\n",
    "def fake_lmdb_builder(fake_data, keys: List[str], lmdb_path: str = \"S2_lmdb.db\"):\n",
    "    max_size = 2**40  # 1TebiByte\n",
    "    env = lmdb.open(str(lmdb_path), map_size=max_size, readonly=False)\n",
    "\n",
    "    with Progress() as progress:\n",
    "        task = progress.add_task(\"Building LMDB archive\", total=len(keys))\n",
    "        for key in keys:\n",
    "            with env.begin(write=True) as txn:\n",
    "                txn.put(key.encode(\"utf-8\"), fake_data)\n",
    "                progress.update(task, advance=1)\n",
    "        env.close()\n",
    "\n",
    "\n",
    "keys = [f\"{i:05}\" for i in range(TOTAL_TEST_SIZE)]\n",
    "# generate fake data and keys\n",
    "# fake_lmdb_builder(s2_patch.dumps(), keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fake_lmdb(keys, lmdb_path=\"S2_lmdb.db\"):\n",
    "    # readahead should be True if dataset fits in RAM\n",
    "    # otherwise it may be faster to set readahead = False\n",
    "    # as readonly=True no need for `locking` which _should_ take longer if lock=True\n",
    "    env = lmdb.open(str(lmdb_path), readonly=True, readahead=True, lock=False)\n",
    "    # possible optimization use single call to\n",
    "    # getmulti(keys) instead of a new thread with a single element as transaction?\n",
    "\n",
    "    for key in keys:\n",
    "        with env.begin() as txn:\n",
    "            byteflow = txn.get(key.encode(\"utf-8\"))\n",
    "            s2_patch = BigEarthNet_S2_Patch.loads(byteflow)\n",
    "\n",
    "\n",
    "# ~4 sek to pass through 6600 * 2\n",
    "read_fake_lmdb(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_to_ben_perf(TOTAL_TEST_SIZE, 4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from bigearthnet_encoder.squirrel_ext import (\n",
    "    MyMessagePackDriver,\n",
    "    _patch_interface_to_dict,\n",
    ")\n",
    "\n",
    "s2_patch_dict = _patch_interface_to_dict(s2_patch)\n",
    "\n",
    "\n",
    "def gen_shards():\n",
    "    while True:\n",
    "        yield s2_patch_dict\n",
    "\n",
    "\n",
    "it = IterableSource(iter(gen_shards()))\n",
    "url = \"dummy\"\n",
    "# Other supported compressions:\n",
    "# fsspec.compression.available_compressions()\n",
    "# [None, 'zip', 'bz2', 'gzip', 'lzma', 'xz']\n",
    "compression = \"None\"\n",
    "SAVE_URL = f\"{url}_{compression}\"\n",
    "p = Path(SAVE_URL)\n",
    "shutil.rmtree(p)\n",
    "msgpack_driver = MyMessagePackDriver(SAVE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigearthnet_encoder.squirrel_ext import _write_s2_msgpack\n",
    "from bigearthnet_common.example_data import get_s2_example_folder_path\n",
    "from bigearthnet_common.base import get_s2_patch_directories\n",
    "from squirrel.iterstream import IterableSource\n",
    "from pathlib import Path\n",
    "\n",
    "# s2_path = get_s2_example_folder_path()\n",
    "s2_path = Path(\"~/datasets/BigEarthNet-v1.0/BigEarthNet-v1.0\").expanduser()\n",
    "patch_paths = get_s2_patch_directories(s2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_paths = patch_paths[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_write_s2_msgpack(patch_paths, \"dummy_None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(msgpack_driver.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_to_ben_perf(6600, 60 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# to_shard = partial(msgpack_driver.store.set, compression=None)\n",
    "# batches = it.take(TOTAL_TEST_SIZE).batched(SHARD_SIZE, drop_last_if_not_full=False).map(to_shard).join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GZIP: 6.5s for pass-through\n",
    "# ~797MB\n",
    "# 6.8\n",
    "# with not prefetch_buffer 6.8s\n",
    "\n",
    "# read using the messagepack driver\n",
    "\n",
    "it_msg_pack = msgpack_driver.get_iter()\n",
    "for item in it_msg_pack.take(10):\n",
    "    # np.mean(item[\"10m_bands\"])\n",
    "    print(item[\"patch_name\"])\n",
    "    print(item[\"B01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_to_ben_perf(TOTAL_TEST_SIZE, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cd77a3d0626c541194178d938a490eb8e66024b704a0471b646ad79929cad0c"
  },
  "kernelspec": {
   "display_name": "bigearthnet_encoder",
   "language": "python",
   "name": "bigearthnet_encoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
